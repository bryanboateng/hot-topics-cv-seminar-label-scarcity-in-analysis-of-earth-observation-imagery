{
	"cells": [
		{
			"attachments": {},
			"cell_type": "markdown",
			"id": "511a1806",
			"metadata": {},
			"source": [
				"## Imports"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"id": "7960632c",
			"metadata": {
				"collapsed": false,
				"pycharm": {
					"name": "#%%\n"
				}
			},
			"outputs": [],
			"source": [
				"import os\n",
				"import time\n",
				"import torch\n",
				"import torchvision"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"id": "56bc6de5",
			"metadata": {},
			"source": [
				"## Device"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"id": "d3af808e",
			"metadata": {
				"collapsed": false,
				"pycharm": {
					"name": "#%%\n"
				}
			},
			"outputs": [],
			"source": [
				"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
				"print(device)"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"id": "5a7c9595",
			"metadata": {},
			"source": [
				"## Paths"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"id": "4e888e33",
			"metadata": {
				"collapsed": false,
				"pycharm": {
					"name": "#%%\n"
				}
			},
			"outputs": [],
			"source": [
				"training_data_directory = \"../grouped-data/train/\"\n",
				"testing_data_directory = \"../grouped-data/test/\"\n",
				"model_directory = \"./models/\"\n",
				"image_name_list_path = \"./xview2.txt\""
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"id": "27e331e4",
			"metadata": {},
			"source": [
				"## Load Data"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"id": "62fd7e9a",
			"metadata": {
				"collapsed": false,
				"pycharm": {
					"name": "#%%\n"
				}
			},
			"outputs": [],
			"source": [
				"def get_first_n_lines(filename, n):\n",
				"    with open(filename, \"r\") as file:\n",
				"        wanted_image_names = set(next(file).strip() for _ in range(n))\n",
				"\n",
				"    subset_indices = []\n",
				"    for idx, img_data in enumerate(training_data.imgs):\n",
				"        if img_data[0].split(\"/\")[-1] in wanted_image_names:\n",
				"            subset_indices.append(idx)\n",
				"            if len(subset_indices) == n:\n",
				"                break  # Stop the loop once we have found n matches\n",
				"\n",
				"    return torch.utils.data.DataLoader(\n",
				"        torch.utils.data.Subset(training_data, subset_indices),\n",
				"        batch_size=12,\n",
				"        shuffle=True,\n",
				"        num_workers=8,\n",
				"    )\n",
				"\n",
				"\n",
				"training_data = torchvision.datasets.ImageFolder(\n",
				"    training_data_directory,\n",
				"    torchvision.transforms.Compose(\n",
				"        [\n",
				"            torchvision.transforms.Resize((224, 224)),\n",
				"            torchvision.transforms.ToTensor(),\n",
				"            torchvision.transforms.Normalize(\n",
				"                [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
				"            ),\n",
				"        ]\n",
				"    ),\n",
				")\n",
				"\n",
				"\n",
				"training_data_loaders = [\n",
				"    get_first_n_lines(image_name_list_path, n) for n in [1,2]\n",
				"]\n",
				"\n",
				"testing_data = torchvision.datasets.ImageFolder(\n",
				"    testing_data_directory,\n",
				"    torchvision.transforms.Compose(\n",
				"        [\n",
				"            torchvision.transforms.Resize((224, 224)),\n",
				"            torchvision.transforms.ToTensor(),\n",
				"            torchvision.transforms.Normalize(\n",
				"                [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
				"            ),\n",
				"        ]\n",
				"    ),\n",
				")\n",
				"testing_data_loader = torch.utils.data.DataLoader(\n",
				"    testing_data,\n",
				"    batch_size=12,\n",
				"    shuffle=False,\n",
				"    num_workers=8,\n",
				")"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"id": "a41b606d",
			"metadata": {},
			"source": [
				"## Dataset Size"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"id": "65620aff",
			"metadata": {
				"collapsed": false,
				"pycharm": {
					"name": "#%%\n"
				}
			},
			"outputs": [],
			"source": [
				"for training_data_loader in training_data_loaders:\n",
				"    print(\"Training dataset size:\", len(training_data_loader.dataset))\n",
				"print(\"Testing dataset size:\", len(testing_data_loader.dataset))"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"id": "92ed61d1",
			"metadata": {},
			"source": [
				"## Train Model"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"id": "1e3c9452",
			"metadata": {
				"collapsed": false,
				"pycharm": {
					"name": "#%%\n"
				}
			},
			"outputs": [],
			"source": [
				"def format_duration(seconds):\n",
				"    # Calculate the time components\n",
				"    components = [\n",
				"        (\"w\", seconds // 604800),  # 1 week is 604800 seconds\n",
				"        (\"d\", seconds // 86400 % 7),  # 1 day is 86400 seconds\n",
				"        (\"h\", seconds // 3600 % 24),  # 1 hour is 3600 seconds\n",
				"        (\"min\", seconds // 60 % 60),  # 1 minute is 60 seconds\n",
				"        (\"s\", round(seconds % 60, 2)),\n",
				"    ]\n",
				"\n",
				"    # Only include non-zero components\n",
				"    components = [(label, value) for label, value in components if value > 0]\n",
				"\n",
				"    # Format the string\n",
				"    return \", \".join(f\"{value}{label}\" for label, value in components)\n",
				"\n",
				"\n",
				"def print_phase_info(is_training, total_loss, correct_prediction_count):\n",
				"    dataset_length = len(\n",
				"        training_data_loader.dataset if is_training else testing_data_loader.dataset\n",
				"    )\n",
				"    print(\n",
				"        \"    {} Epoch {} done. Loss: {:.2f}, Accuracy: {:.2f}%, Phase Duration: {}, Total Duration: {}\".format(\n",
				"            \"Training\" if is_training else \"Testing\",\n",
				"            epoch,\n",
				"            total_loss / dataset_length,\n",
				"            (correct_prediction_count / dataset_length) * 100.0,\n",
				"            format_duration(\n",
				"                time.time()\n",
				"                - (training_start_time if is_training else testing_start_time)\n",
				"            ),\n",
				"            format_duration(time.time() - start_time),\n",
				"        )\n",
				"    )\n",
				"\n",
				"\n",
				"for i, training_data_loader in enumerate(training_data_loaders):\n",
				"    model = torchvision.models.resnet18(weights=torchvision.models.ResNet18_Weights.DEFAULT)\n",
				"    input_feature_count = model.fc.in_features\n",
				"    output_feature_count = 5\n",
				"    model.fc = torch.nn.Linear(input_feature_count, output_feature_count)\n",
				"    model = model.to(device)\n",
				"    criterion = torch.nn.CrossEntropyLoss()\n",
				"    optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
				"\n",
				"    epoch_count = 1\n",
				"    start_time = time.time()\n",
				"    for epoch in range(epoch_count):\n",
				"        epoch_start_time = time.time()\n",
				"        print(\"Epoch {} running.\".format(epoch))\n",
				"        \"\"\" Training Phase \"\"\"\n",
				"        training_start_time = time.time()\n",
				"        model.train()\n",
				"        total_loss = 0.0\n",
				"        correct_prediction_count = 0\n",
				"        for inputs, targets in training_data_loader:\n",
				"            inputs = inputs.to(device)\n",
				"            targets = targets.to(device)\n",
				"\n",
				"            # Foward pass\n",
				"            outputs = model(inputs)\n",
				"            _, predictions = torch.max(outputs, 1)\n",
				"            loss = criterion(outputs, targets)\n",
				"\n",
				"            # Back-propagation\n",
				"            optimizer.zero_grad()\n",
				"            loss.backward()\n",
				"            optimizer.step()\n",
				"\n",
				"            total_loss += loss.item() * inputs.size(0)\n",
				"            correct_prediction_count += torch.sum(predictions == targets.data)\n",
				"        print_phase_info(True, total_loss, correct_prediction_count)\n",
				"\n",
				"        \"\"\" Testing Phase \"\"\"\n",
				"        testing_start_time = time.time()\n",
				"        model.eval()\n",
				"        with torch.no_grad():\n",
				"            total_loss = 0.0\n",
				"            correct_prediction_count = 0\n",
				"            for inputs, targets in testing_data_loader:\n",
				"                inputs = inputs.to(device)\n",
				"                targets = targets.to(device)\n",
				"\n",
				"                outputs = model(inputs)\n",
				"                _, predictions = torch.max(outputs, 1)\n",
				"                loss = criterion(outputs, targets)\n",
				"\n",
				"                total_loss += loss.item() * inputs.size(0)\n",
				"                correct_prediction_count += torch.sum(predictions == targets.data)\n",
				"            print_phase_info(False, total_loss, correct_prediction_count)\n",
				"\n",
				"        print(\n",
				"            \"Epoch {} done. Epoch Duration: {}, Total Duration: {}\".format(\n",
				"                epoch,\n",
				"                format_duration(time.time() - epoch_start_time),\n",
				"                format_duration(time.time() - start_time),\n",
				"            )\n",
				"        )\n",
				"        print(\"--------------------------------------------\")\n",
				"    torch.save(model.state_dict(), os.path.join(model_directory, str(i)))"
			]
		}
	],
	"metadata": {
		"kernelspec": {
			"display_name": "Python 3 (ipykernel)",
			"language": "python",
			"name": "python3"
		},
		"language_info": {
			"codemirror_mode": {
				"name": "ipython",
				"version": 3
			},
			"file_extension": ".py",
			"mimetype": "text/x-python",
			"name": "python",
			"nbconvert_exporter": "python",
			"pygments_lexer": "ipython3",
			"version": "3.11.3"
		}
	},
	"nbformat": 4,
	"nbformat_minor": 5
}
