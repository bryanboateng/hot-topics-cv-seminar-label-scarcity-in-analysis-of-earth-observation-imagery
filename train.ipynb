{
	"cells": [
		{
			"attachments": {},
			"cell_type": "markdown",
			"id": "511a1806",
			"metadata": {
				"pycharm": {
					"name": "#%% md\n"
				}
			},
			"source": [
				"## Imports\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"id": "7960632c",
			"metadata": {
				"collapsed": false,
				"pycharm": {
					"name": "#%%\n"
				}
			},
			"outputs": [],
			"source": [
				"import torch\n",
				"import torchvision\n",
				"import matplotlib.pylab as plt\n",
				"from datetime import datetime\n",
				"import os\n",
				"import time"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"id": "56bc6de5",
			"metadata": {
				"pycharm": {
					"name": "#%% md\n"
				}
			},
			"source": [
				"## Device\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"id": "d3af808e",
			"metadata": {
				"collapsed": false,
				"pycharm": {
					"name": "#%%\n"
				}
			},
			"outputs": [],
			"source": [
				"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
				"print(device)"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"id": "5a7c9595",
			"metadata": {
				"pycharm": {
					"name": "#%% md\n"
				}
			},
			"source": [
				"## Paths\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"id": "4e888e33",
			"metadata": {
				"collapsed": false,
				"pycharm": {
					"name": "#%%\n"
				}
			},
			"outputs": [],
			"source": [
				"training_data_directory_path = \"../grouped-data/train/\"\n",
				"testing_data_directory_path = \"../minimal-grouped-data/test/\"\n",
				"models_directory_path = \"./models/\"\n",
				"image_name_list_path = \"./xview2.txt\""
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"id": "27e331e4",
			"metadata": {
				"pycharm": {
					"name": "#%% md\n"
				}
			},
			"source": [
				"## Load Testing Data\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"id": "8227762f",
			"metadata": {
				"pycharm": {
					"name": "#%%\n"
				}
			},
			"outputs": [],
			"source": [
				"testing_data = torchvision.datasets.ImageFolder(\n",
				"    testing_data_directory_path,\n",
				"    torchvision.transforms.Compose(\n",
				"        [\n",
				"            torchvision.transforms.Resize((224, 224)),\n",
				"            torchvision.transforms.ToTensor(),\n",
				"            torchvision.transforms.Normalize(\n",
				"                [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
				"            ),\n",
				"        ]\n",
				"    ),\n",
				")\n",
				"testing_data_loader = torch.utils.data.DataLoader(\n",
				"    testing_data,\n",
				"    batch_size=12,\n",
				"    shuffle=False,\n",
				"    num_workers=8,\n",
				")"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"id": "05063fba",
			"metadata": {
				"pycharm": {
					"name": "#%% md\n"
				}
			},
			"source": [
				"## Load Training Data\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"id": "62fd7e9a",
			"metadata": {
				"collapsed": false,
				"pycharm": {
					"name": "#%%\n"
				}
			},
			"outputs": [],
			"source": [
				"def get_first_n_lines(filename, n):\n",
				"    with open(filename, \"r\") as file:\n",
				"        wanted_image_names = set(next(file).strip() for _ in range(n))\n",
				"\n",
				"    subset_indices = []\n",
				"    for idx, img_data in enumerate(training_data.imgs):\n",
				"        if img_data[0].split(\"/\")[-1] in wanted_image_names:\n",
				"            subset_indices.append(idx)\n",
				"            if len(subset_indices) == n:\n",
				"                break  # Stop the loop once we have found n matches\n",
				"\n",
				"    return torch.utils.data.DataLoader(\n",
				"        torch.utils.data.Subset(training_data, subset_indices),\n",
				"        batch_size=12,\n",
				"        shuffle=True,\n",
				"        num_workers=8,\n",
				"    )\n",
				"\n",
				"\n",
				"training_data = torchvision.datasets.ImageFolder(\n",
				"    training_data_directory_path,\n",
				"    torchvision.transforms.Compose(\n",
				"        [\n",
				"            torchvision.transforms.Resize((224, 224)),\n",
				"            torchvision.transforms.ToTensor(),\n",
				"            torchvision.transforms.Normalize(\n",
				"                [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
				"            ),\n",
				"        ]\n",
				"    ),\n",
				")\n",
				"\n",
				"named_training_data_loaders = {\n",
				"    data_set_name: get_first_n_lines(image_name_list_path, image_count)\n",
				"    for (data_set_name, image_count) in [(\"baseline\", 4), (\"bryan\", 4)]\n",
				"}"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"id": "a41b606d",
			"metadata": {
				"pycharm": {
					"name": "#%% md\n"
				}
			},
			"source": [
				"## Dataset Size\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"id": "65620aff",
			"metadata": {
				"collapsed": false,
				"pycharm": {
					"name": "#%%\n"
				}
			},
			"outputs": [],
			"source": [
				"for name, training_data_loader in named_training_data_loaders.items():\n",
				"    print(f'Training dataset \"{name}\" size:', len(training_data_loader.dataset))\n",
				"print(\"--------------\")\n",
				"print(\"Testing dataset size:\", len(testing_data_loader.dataset))"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"id": "92ed61d1",
			"metadata": {
				"pycharm": {
					"name": "#%% md\n"
				}
			},
			"source": [
				"## Train Model\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"id": "1e3c9452",
			"metadata": {
				"collapsed": false,
				"pycharm": {
					"name": "#%%\n"
				}
			},
			"outputs": [],
			"source": [
				"import model_creation\n",
				"import logging\n",
				"\n",
				"\n",
				"def change_log_file_path(logger, new_path):\n",
				"    for handler in logger.handlers[:]:  # copy the handlers list\n",
				"        if isinstance(\n",
				"            handler, logging.FileHandler\n",
				"        ):  # check if handler is a FileHandler\n",
				"            logger.removeHandler(handler)  # remove the handler from the logger\n",
				"\n",
				"    file_handler = logging.FileHandler(new_path)  # create a new FileHandler\n",
				"    file_handler.setLevel(logging.INFO)  # set the log level of the handler\n",
				"    logger.addHandler(file_handler)  # add the handler to the logger\n",
				"\n",
				"\n",
				"epoch_count = 2\n",
				"logging.basicConfig(level=logging.INFO)\n",
				"logger = logging.getLogger()\n",
				"\n",
				"for i, (dataset_name, training_data_loader) in enumerate(\n",
				"    named_training_data_loaders.items()\n",
				"):\n",
				"    dataset_length = len(training_data_loader.dataset)\n",
				"    model_descriptor = (\n",
				"        dataset_name\n",
				"        + f\"_size{dataset_length}\"\n",
				"        + f\"_targetEpochCount{epoch_count}\"\n",
				"        + f\"_creationStart{datetime.utcnow().replace(microsecond=0).isoformat()}Z\"\n",
				"    )\n",
				"    model_directory_path = os.path.join(models_directory_path, model_descriptor)\n",
				"    model_info_directory_path = os.path.join(model_directory_path, \"_info\")\n",
				"\n",
				"    # Create the directory if it doesn't already exist\n",
				"    os.makedirs(model_info_directory_path, exist_ok=True)\n",
				"    change_log_file_path(\n",
				"        logger, os.path.join(model_info_directory_path, \"durations.log\")\n",
				"    )\n",
				"    logger.info(f\"Creating {model_descriptor}\")\n",
				"\n",
				"    model = torchvision.models.resnet18(\n",
				"        weights=torchvision.models.ResNet18_Weights.DEFAULT\n",
				"    )\n",
				"    input_feature_count = model.fc.in_features\n",
				"    output_feature_count = 5\n",
				"    model.fc = torch.nn.Linear(input_feature_count, output_feature_count)\n",
				"    model = model.to(device)\n",
				"    criterion = torch.nn.CrossEntropyLoss()\n",
				"    optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
				"\n",
				"    training_losses = []\n",
				"    training_accuracies = []\n",
				"    testing_losses = []\n",
				"    testing_accuracies = []\n",
				"    model_creation_start_time = time.time()\n",
				"    for epoch in range(1, epoch_count + 1):\n",
				"        epoch_start_time = time.time()\n",
				"        logger.info(\"Epoch {} running.\".format(epoch))\n",
				"        training_start_time = time.time()\n",
				"        loss, accuracy = model_creation.train_model(\n",
				"            training_data_loader, model, criterion, optimizer\n",
				"        )\n",
				"        model_creation.log_duration(\n",
				"            logger, True, epoch, training_start_time, model_creation_start_time\n",
				"        )\n",
				"        training_losses.append(loss)\n",
				"        training_accuracies.append(accuracy)\n",
				"        model_name = (\n",
				"            dataset_name\n",
				"            + f\"_size{dataset_length}\"\n",
				"            + f\"_epoch{epoch}Of{epoch_count}\"\n",
				"            + f\"_{datetime.utcnow().replace(microsecond=0).isoformat()}Z\"\n",
				"            + \".pth\"\n",
				"        )\n",
				"        model_creation.export_model(\n",
				"            model,\n",
				"            model_name,\n",
				"            model_directory_path,\n",
				"        )\n",
				"        model_creation.export_loss_and_accuracy(\n",
				"            training_losses,\n",
				"            training_accuracies,\n",
				"            testing_losses,\n",
				"            testing_accuracies,\n",
				"            model_descriptor,\n",
				"            model_info_directory_path,\n",
				"        )\n",
				"        model_creation.plot_loss(\n",
				"            training_losses, testing_losses, model_descriptor, model_info_directory_path\n",
				"        )\n",
				"        testing_start_time = time.time()\n",
				"        loss, accuracy = model_creation.test_model(\n",
				"            model, testing_data_loader, criterion\n",
				"        )\n",
				"        testing_losses.append(loss)\n",
				"        testing_accuracies.append(accuracy)\n",
				"        model_creation.export_loss_and_accuracy(\n",
				"            training_losses,\n",
				"            training_accuracies,\n",
				"            testing_losses,\n",
				"            testing_accuracies,\n",
				"            model_descriptor,\n",
				"            model_info_directory_path,\n",
				"        )\n",
				"        model_creation.log_duration(\n",
				"            logger, False, epoch, testing_start_time, model_creation_start_time\n",
				"        )\n",
				"        model_creation.plot_loss(\n",
				"            training_losses, testing_losses, model_descriptor, model_info_directory_path\n",
				"        )\n",
				"\n",
				"        logger.info(\n",
				"            \"Epoch {} done. Epoch Duration: {}, Total Duration: {}\".format(\n",
				"                epoch,\n",
				"                model_creation.format_duration(time.time() - epoch_start_time),\n",
				"                model_creation.format_duration(time.time() - model_creation_start_time),\n",
				"            )\n",
				"        )\n",
				"        logger.info(\"--------------------------------------------\")\n",
				"    logger.info(\"Done creating model\")\n",
				"    plt.ioff()\n",
				"    plt.show()"
			]
		}
	],
	"metadata": {
		"kernelspec": {
			"display_name": "Python 3 (ipykernel)",
			"language": "python",
			"name": "python3"
		},
		"language_info": {
			"codemirror_mode": {
				"name": "ipython",
				"version": 3
			},
			"file_extension": ".py",
			"mimetype": "text/x-python",
			"name": "python",
			"nbconvert_exporter": "python",
			"pygments_lexer": "ipython3",
			"version": "3.11.3"
		}
	},
	"nbformat": 4,
	"nbformat_minor": 5
}
