{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7960632c",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import sklearn\n",
    "import time\n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3af808e",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e888e33",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "training_data_directory = \"../grouped-data/train/\"\n",
    "testing_data_directory = \"../grouped-data/test/\"\n",
    "model_name = \"./resnet_18.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fd7e9a",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "training_data_loader = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.ImageFolder(\n",
    "        training_data_directory,\n",
    "        torchvision.transforms.Compose(\n",
    "            [\n",
    "                torchvision.transforms.Resize((224, 224)),\n",
    "                torchvision.transforms.ToTensor(),\n",
    "                torchvision.transforms.Normalize(\n",
    "                    [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
    "                ),\n",
    "            ]\n",
    "        ),\n",
    "    ),\n",
    "    batch_size=12,\n",
    "    shuffle=True,\n",
    "    num_workers=8,\n",
    ")\n",
    "\n",
    "testing_data = torchvision.datasets.ImageFolder(\n",
    "    testing_data_directory,\n",
    "    torchvision.transforms.Compose(\n",
    "        [\n",
    "            torchvision.transforms.Resize((224, 224)),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize(\n",
    "                [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
    "            ),\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "testing_data_loader = torch.utils.data.DataLoader(\n",
    "    testing_data,\n",
    "    batch_size=12,\n",
    "    shuffle=False,\n",
    "    num_workers=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65620aff",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Training dataset size:\", len(training_data_loader.dataset))\n",
    "print(\"Testing dataset size:\", len(testing_data_loader.dataset))\n",
    "print(\"Class names:\", training_data_loader.dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93265168",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet18(weights=torchvision.models.ResNet18_Weights.DEFAULT)\n",
    "input_feature_count = model.fc.in_features\n",
    "output_feature_count = 5\n",
    "model.fc = torch.nn.Linear(input_feature_count, output_feature_count)\n",
    "model = model.to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3c9452",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def format_duration(seconds):\n",
    "    # Calculate the time components\n",
    "    components = [\n",
    "        (\"w\", seconds // 604800),  # 1 week is 604800 seconds\n",
    "        (\"d\", seconds // 86400 % 7),  # 1 day is 86400 seconds\n",
    "        (\"h\", seconds // 3600 % 24),  # 1 hour is 3600 seconds\n",
    "        (\"min\", seconds // 60 % 60),  # 1 minute is 60 seconds\n",
    "        (\"s\", round(seconds % 60, 2)),\n",
    "    ]\n",
    "\n",
    "    # Only include non-zero components\n",
    "    components = [(label, value) for label, value in components if value > 0]\n",
    "\n",
    "    # Format the string\n",
    "    return \", \".join(f\"{value}{label}\" for label, value in components)\n",
    "\n",
    "\n",
    "def print_phase_info(is_training, total_loss, correct_prediction_count):\n",
    "    dataset_length = len(\n",
    "        training_data_loader.dataset if is_training else testing_data_loader.dataset\n",
    "    )\n",
    "    print(\n",
    "        \"    {} Epoch {} done. Loss: {:.2f}, Accuracy: {:.2f}%, Phase Duration: {}, Total Duration: {}\".format(\n",
    "            \"Training\" if is_training else \"Testing\",\n",
    "            epoch,\n",
    "            total_loss / dataset_length,\n",
    "            (correct_prediction_count / dataset_length) * 100.0,\n",
    "            format_duration(time.time() - (training_start_time if is_training else testing_start_time)),\n",
    "            format_duration(time.time() - start_time),\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "epoch_count = 2\n",
    "start_time = time.time()\n",
    "for epoch in range(epoch_count):\n",
    "    epoch_start_time = time.time()\n",
    "    print(\"Epoch {} running.\".format(epoch))\n",
    "    \"\"\" Training Phase \"\"\"\n",
    "    training_start_time = time.time()\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct_prediction_count = 0\n",
    "    for inputs, targets in training_data_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # Foward pass\n",
    "        outputs = model(inputs)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # Back-propagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * inputs.size(0)\n",
    "        correct_prediction_count += torch.sum(predictions == targets.data)\n",
    "    print_phase_info(True, total_loss, correct_prediction_count)\n",
    "\n",
    "    \"\"\" Testing Phase \"\"\"\n",
    "    testing_start_time = time.time()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0.0\n",
    "        correct_prediction_count = 0\n",
    "        for inputs, targets in testing_data_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "            correct_prediction_count += torch.sum(predictions == targets.data)\n",
    "        print_phase_info(False, total_loss, correct_prediction_count)\n",
    "\n",
    "    print(\n",
    "        \"Epoch {} done. Epoch Duration: {}, Total Duration: {}\".format(\n",
    "            epoch,\n",
    "            format_duration(time.time() - epoch_start_time),\n",
    "            format_duration(time.time() - start_time),\n",
    "        )\n",
    "    )\n",
    "    print(\"--------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3e2935",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec593ed",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet18(weights=torchvision.models.ResNet18_Weights.DEFAULT)\n",
    "input_feature_count = model.fc.in_features\n",
    "output_feature_count = 5\n",
    "model.fc = torch.nn.Linear(input_feature_count, output_feature_count)\n",
    "model.load_state_dict(torch.load(model_name))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e65e749",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    inputs, targets = next(\n",
    "        iter(\n",
    "            torch.utils.data.DataLoader(\n",
    "                testing_data,\n",
    "                batch_size=len(testing_data),\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    inputs = inputs.to(device)\n",
    "    outputs = model(inputs)\n",
    "    _, predictions = torch.max(outputs, 1)\n",
    "    confusion_matrix = sklearn.metrics.confusion_matrix(targets, predictions)\n",
    "    overall_accuracy = confusion_matrix.trace() / confusion_matrix.sum()\n",
    "    average_accuracy = (\n",
    "        confusion_matrix.diagonal() / confusion_matrix.sum(axis=1)\n",
    "    ).mean()\n",
    "    confusion_matrix_display = sklearn.metrics.ConfusionMatrixDisplay(\n",
    "        confusion_matrix=confusion_matrix\n",
    "    )\n",
    "    confusion_matrix_display.plot()\n",
    "    matplotlib.pyplot.title(\"Confusion Matrix\")\n",
    "    matplotlib.pyplot.show()\n",
    "    print(\"Overall accuracy: {:.2f}%\".format(overall_accuracy * 100))\n",
    "    print(\"Average accuracy: {:.2f}%\".format(average_accuracy * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}